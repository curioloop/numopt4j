/*
 * Copyright (c) 2025 curioloop. All rights reserved.
 *
 * NNLS (Non-Negative Least-Squares)
 *
 * Solves a least-squares problem ğš–ğš’ğš— â€– ğ€ğ± - ğ› â€–â‚‚ subject to ğ± â‰¥ 0 with active-set method.
 *   - ğ€ is m Ã— n column-major matrix with ğš›ğšŠğš—ğš”(ğ€) = n (the columns of ğ€ are linearly independent)
 *   - ğ± âˆˆ â„â¿
 *   - ğ› âˆˆ â„áµ
 *
 * There are two index sets â„¤(zero) and â„™(pivot):
 *   - ğ±â±¼ = 0, j âˆˆ â„¤ : variable indexed in active set â„¤ will be held at the value zero
 *   - ğ±â±¼ > 0, j âˆˆ â„™ : variable indexed in passive set â„™ will be free to take any positive value
 *
 * When ğ±â±¼ < 0 occurred, NNLS will change its value to a non-negative value and move its index j from â„™ to â„¤.
 *
 * The m Ã— k matrix ğ€â‚– is a subset columns of ğ€ defined by indices of â„™.
 * NNLS applies QR decomposition ğğ€â‚– = [ğ‘â‚–áµ€:O]áµ€ to solve least-squares [ğ€â‚–:O]ğ± â‰… ğ›
 * where ğ is m Ã— m orthogonal matrix and ğ‘â‚– is k Ã— k upper triangular matrix.
 *
 * Once ğ and ğ‘â‚– is computed, the solution is given by ğ±ß® = [ğ‘â‚–â»Â¹:O]ğğ›.
 *
 * Let ğ› = [ğ›â‚:ğ›â‚‚] (ğ›â‚ âˆˆ â„â¿, ğ›â‚‚ âˆˆ â„áµâ»â¿) and rewrite ğš–ğš’ğš—â€– ğ€ğ± - ğ› â€–â‚‚ to ğš–ğš’ğš—â€– ğáµ€ğ[ğ‘â‚™:O]ğ± - ğáµ€[ğ›â‚:ğ›â‚‚] â€–â‚‚
 *   - the solution ğ± satisfied ğ‘â‚™ğ± = ğáµ€ğ›â‚ (ğáµ€ğ = ğˆâ‚˜)
 *   - the residual is given by ğ« = ğğáµ€[ğ›â‚:ğ›â‚‚]áµ€ - ğ[ğ‘â‚™áµ€ğ±:O]áµ€ = ğ[O:ğáµ€ğ›â‚‚]
 *   - the norm of residual is given by â€– ğ« â€–â‚‚ = â€– ğáµ€ğ›â‚‚ â€–â‚‚
 *
 * The input will be treated as a whole m Ã— (n+1) working space ğ[ğ€:ğ›] where
 *   - space of matrix ğ€ will be used to store the ğğ€ result
 *   - space of vector ğ› will be used to store the ğğ› result
 *
 * Optimality Conditions
 * ---------------------
 * Given a problem ğš–ğš’ğš— ğ’‡(ğ±) subject to ğ’‰â±¼(ğ±) = 0 (j = 1 Â·Â·Â· mâ‚‘) and ğ’ˆâ±¼(ğ±) â‰¤ 0 (j = mâ‚‘+1 Â·Â·Â· m),
 * its optimality at location ğ±áµ are given by below KKT conditions:
 *   - ğœµâ„’(ğ±áµ,ğ›Œáµ) = ğœµğ’‡(ğ±áµ) + âˆ‘ğ›Œáµâ±¼ğœµğ’ˆâ±¼(ğ±áµ) = 0
 *   - ğ’ˆâ±¼(ğ±áµ) = 0   (j = 1 Â·Â·Â· mâ‚‘)
 *   - ğ’ˆâ±¼(ğ±áµ) â‰¤ 0   (j = mâ‚‘+1 Â·Â·Â· m)
 *   - ğ›Œáµâ±¼ â‰¥ 0      (j = mâ‚‘+1 Â·Â·Â· m)
 *   - ğ›Œáµâ±¼ğ’ˆâ±¼(ğ±) = 0  (j = mâ‚‘+1 Â·Â·Â· m)
 *
 * and substitute NNLS to the KKT conditions:
 *   - ğ’‡(ğ±) = Â½ğ±áµ€ğ€ğ± - 2ğ›áµ€ğ€ğ± + Â½ğ›áµ€ğ›  â†’  ğœµğ’‡(ğ±) = ğ€áµ€(ğ€ğ± + ğ›)
 *   - ğ’ˆâ±¼(ğ±) = 0  (j = 1 Â·Â·Â· mâ‚‘)    â†’  ğœµğ’ˆâ±¼(ğ±) = 0
 *   - ğ’ˆâ±¼(ğ±) = -ğ±â±¼ (j = mâ‚‘+1 Â·Â·Â· m) â†’  ğœµğ’ˆâ±¼(ğ±) = -1
 *
 * the optimality conditions for NNLS are given:
 *   - ğœµâ„’(ğ±áµ,ğ›Œáµ) = ğ€áµ€(ğ€ğ±áµ + ğ›) - âˆ‘ğ›Œáµâ±¼ = 0
 *   - ğ›Œáµâ±¼ â‰¥ 0 âˆ€j
 *   - ğ›Œáµâ±¼ğ’ˆâ±¼(ğ±) = 0 âˆ€j
 *
 * NNLS introduces a dual m-vector ğ° = -ğº = -ğœµğ’‡(ğ±) = ğ€áµ€(ğ› - ğ€ğ±) and optimality is given by:
 *   - ğ°â±¼ = 0, âˆ€j âˆˆ â„™
 *   - ğ°â±¼ â‰¤ 0, âˆ€j âˆˆ â„¤
 *
 * Active Set Method
 * -----------------
 * The optimality of the activity set method is described by the KKT condition.
 *
 * Let ğ±áµ be a feasible vector, the inequality constraints ğ’ˆâ±¼(ğ±áµ) (j = mâ‚‘+1 Â·Â·Â· m) has two status:
 *   - active inequality constraints : ğ’ˆâ±¼(ğ±áµ) = 0
 *   - passive inequality constraints : ğ’ˆâ±¼(ğ±áµ) < 0
 *
 * Recall the ğº describes how ğ’‡(ğ±) change when relaxing constraints ğ’ˆâ±¼(ğ±) â‰¤ 0 â†’ ğ›† with a interruption ğ›† > 0:
 *   - for ğ›Œâ±¼ < 0, relax the ğ’ˆâ±¼(ğ±) will decrease ğ’‡(ğ±)
 *   - for ğ›Œâ±¼ > 0, relax the ğ’ˆâ±¼(ğ±) will increase ğ’‡(ğ±)
 *
 * When we found some active constraints with ğ›Œâ±¼ < 0:
 *   - relax ğ’ˆâ±¼(ğ±) and move it from â„¤ to â„™
 *   - form a new pure equality constrain sub-problem EQP base on new â„¤
 *   - solve EQP with variable elimination method
 *
 * Assume ğ¬ is the EQP solution, then there is ğ’‡(ğ¬) < ğ’‡(ğ±áµ) and:
 *   - if ğ¬ is feasible, update â„¤ and â„™ and solve new EQP until feasible solution is not change
 *   - if ğ¬ is infeasible, we just obtain a descending direction ğ = ğ¬ - ğ±áµ and need to find
 *     a step length Î± > 0 such that ğ±áµ + Î±ğ is feasible.
 *
 * The Î± can be obtained by projecting the infeasible ğ¬ to the boundaries defined by â„™.
 *
 * Once new location ğ±áµâºÂ¹ = ğ±áµ + Î±ğ is determined, update â„¤ and â„™ and solve new EQP again.
 *
 * In case of NNLS, the EQP is a unconstrained least-squares problem ğš–ğš’ğš— Â½â€– ğ€á´¾ğ± - ğ› â€–â‚‚.
 * The matrix ğ€á´¾ is a matrix containing only the variables currently in â„™.
 * Thus the solution is given by ğ¬ = [(ğ€á´¾)áµ€ğ€á´¾]â»Â¹(ğ€á´¾)áµ€ğ› which is actually computed by QR decomposition.
 *
 * Non-negative Solution
 * ---------------------
 * Consider an m Ã— (n+1) augmented matrix [ğ€:ğ›] defined by least-squares problem ğ€ğ± â‰… ğ›.
 *
 * Let ğ be an m Ã— m orthogonal matrix that zeros the sub-diagonal elements in first n-1 cols of ğ€.
 *
 *      n     1       n-1  1   1
 *     â”Œâ”´â”   â”Œâ”´â”      â”Œâ”´â” â”Œâ”´â” â”Œâ”´â”
 *  ğ[  ğ€ ï¹•  ğ› ] = â¡  ğ‘   ğ’”   ğ’– â¤ ]â•´ n-1
 *                  â£  ï¼   ğ’•   ğ’— â¦ ]â•´ m-n+1
 *
 * where ğ‘ is an m Ã— m upper triangular full-rank matrix.
 *
 * Since orthogonal transformation preserves the relationship between the columns of augmented matrix:
 *
 *    (ğğ€)áµ€ğğ› ï¼ ğ€áµ€ğ› ï¼ â¡ ğ‘¹áµ€ ï¼ â¤â¡ ğ’– â¤ ï¼ â¡    ğ‘¹áµ€ğ’–   â¤
 *                      â£ ğ’”áµ€  ğ’•áµ€ â¦â£ ğ’— â¦   â£ ğ’”áµ€ğ’– + ğ’•áµ€ğ’— â¦
 *
 *                              n-1    1
 *                            â”Œâ”€â”€â”´â”€â”€â” â”Œâ”´â”
 *    Assume there is ğ€áµ€ğ› = [ 0 Â·Â·Â· 0  Ï‰ ]áµ€ = [ğ‘¹áµ€ğ’– : ğ’”áµ€ğ’– + ğ’•áµ€ğ’—]áµ€.
 *    Since ğ‘ is non-singular, ğ‘¹áµ€ğ’– has only the trivial solution ğ’– = 0 which means ğ’•áµ€ğ’— = Ï‰.
 *
 * The n-th component of solution to ğ€ğ± â‰… ğ› is the least squares solution of ğ’•ğ±â‚™ â‰… ğ’— which is ğ±â‚™ = ğ’•áµ€ğ’—/ğ’•áµ€ğ’• = Ï‰/ğ’•áµ€ğ’•.
 *
 * Thus when the n-th component of ğ€áµ€ğ› is positive (Ï‰ > 0), then the n-th component of solution satisfied ğ±â‚™ > 0.
 *
 * References
 * ----------
 * C.L. Lawson, R.J. Hanson, 'Solving least squares problems' Prentice Hall, 1974. (revised 1995 edition)
 * Chapters 23, Algorithm 23.10.
 */

#include "optimizer.h"
#include <math.h>
#include <string.h>

/* Factor for checking linear independence */
#define FACTOR 0.01

/* External functions */
extern double h1(int pivot, int start, int m, double* u, int inc);
extern void h2(int pivot, int start, int m, double* u, int incu,
               double up, double* c, int incc, int mdc, int nc);
extern void g1(double a, double b, double* c, double* s, double* sig);
extern void g2(double c, double s, double* a, double* b);
extern double ddot(int n, const double* x, int incx, const double* y, int incy);
extern void daxpy(int n, double a, const double* x, int incx, double* y, int incy);
extern double dnrm2(int n, const double* x, int incx);

/**
 * nnls - Non-Negative Least Squares
 * 
 * Solves ğš–ğš’ğš— â€–ğ€ğ± - ğ›â€–â‚‚ subject to ğ± â‰¥ 0
 * 
 * @param m       Number of rows in ğ€
 * @param n       Number of columns in ğ€
 * @param a       Matrix ğ€ (column-major), modified on return to ğğ€
 * @param mda     Leading dimension of ğ€
 * @param b       Vector ğ›, modified on return to ğğ›
 * @param x       Output: solution vector ğ± of primal problem
 * @param w       Output: dual vector ğ° describing the weight of constraint
 * @param z       Working array of length m
 * @param index   Working array of length n, stores â„™ âˆª â„¤ = {0,...,n-1}
 *                â„™ = index[:np] defines the subset columns of ğ€
 *                â„¤ = index[z1:]
 * @param maxIter Maximum iterations (0 = 3*n)
 * @param rnorm   Output: residual norm â€–ğáµ€ğ›â‚‚â€–â‚‚
 * @return        Status code (0 = success, 1 = exceeded max iterations, negative = error)
 */
int nnls(int m, int n, double* a, int mda,
         double* b, double* x, double* w,
         double* z, int* index, int maxIter,
         double* rnorm) {
    
    int i, ii, ip, iter, iz, izmax, j, jj, jz, l, np, z1;
    double alpha, asave, cc, sm, ss, t, unorm, up, wmax, ztest;
    double* aj;
    
    if (m <= 0 || n <= 0 || mda < m) {
        return -1;  /* Bad argument */
    }
    
    if (maxIter <= 0) {
        maxIter = 3 * n;
    }
    
    np = 0;   /* Number of elements in set â„™ */
    z1 = 0;   /* Start index of set â„¤ */
    
    /* Initialize index = â„™ âˆª â„¤ = {0,...,n-1} */
    for (i = 0; i < n; i++) {
        index[i] = i;
    }
    
    /* Start from ğ± = O and all indices are initially in â„¤ */
    for (i = 0; i < n; i++) {
        x[i] = 0.0;
    }
    
    iter = 0;
    
    /* Main loop: continued until no more active constraints can be set free */
    for (;;) {
        /* Quit if all coefficients are positive: â„¤ = âˆ… (ğ± â‰¥ 0),
           or if m columns of ğ€ have been triangularized */
        if (z1 >= n || np >= m) {
            goto compute_rnorm;
        }
        
        /* Compute components of the dual vector ğ° = ğ€áµ€(ğ› - ğ€ğ±) (negative gradient).
         * Since ğ°â±¼ = 0 for j âˆˆ â„™, we only compute ğ°â±¼ for j âˆˆ â„¤.
         * Given ğ±â±¼ = 0 for j âˆˆ â„¤, the update simplifies to ğ° = ğ€áµ€ğ›. */
        for (iz = z1; iz < n; iz++) {
            j = index[iz];
            w[j] = ddot(m - np, &a[np + mda * j], 1, &b[np], 1);
        }
        
        for (;;) {
            /* Find index t âˆˆ â„¤ such that ğ°â‚œ = ğšŠğš›ğš ğš–ğšŠğš¡ { ğ°â±¼: j âˆˆ â„¤ } */
            wmax = 0.0;
            izmax = 0;
            for (iz = z1; iz < n; iz++) {
                j = index[iz];
                if (w[j] > wmax) {
                    wmax = w[j];
                    izmax = iz;
                }
            }
            
            /* Quit when ğ°â±¼ â‰¤ 0, âˆ€j âˆˆ â„¤ (no more constraint could be relaxed)
             * This indicates satisfaction of the Kuhn-Tucker conditions */
            if (wmax <= 0.0) {
                goto compute_rnorm;
            }
            
            /* Move index t from â„¤ to â„™ */
            iz = izmax;
            j = index[iz];
            aj = &a[mda * j];
            
            /* Given j-th column of ğ€, compute corresponding Householder vector ğ®.
             * Save the pivot-th component of j-th column ğ€â‚šâ±¼. */
            asave = aj[np];
            up = h1(np, np + 1, m, aj, 1);
            /* Now the pivot-th component of j-th column is (ğğ€)â‚šâ±¼.
             * The pivot-th component of ğ® is returned as ğ®â‚š. */
            
            /* Check new diagonal element to avoid near linear dependence */
            unorm = dnrm2(np, aj, 1);  /* â€–ğ®â€–â‚‚ */
            if (fabs(aj[np]) * FACTOR >= unorm * EPS) {
                /* Column j is sufficiently independent.
                 * Compute Householder transformation z = ğğ› = [-Ïƒâ€–ğ›â€–â‚‚ 0 Â·Â·Â· 0]áµ€ */
                memcpy(z, b, m * sizeof(double));
                h2(np, np + 1, m, aj, 1, up, z, 1, 1, 1);
                
                /* Solve ğ(ğ€ğ±)â±¼ â‰… ğğ›â±¼ for proposed new value for ğ±â±¼
                 * ğ± = (ğğ€)âºğğ› */
                ztest = z[np] / aj[np];
                
                if (ztest > 0.0) {
                    /* Accept j: ğ±â±¼ > 0 */
                    
                    /* Update b = ğğ› */
                    memcpy(b, z, m * sizeof(double));
                    
                    /* Move j from â„¤ to â„™ */
                    index[iz] = index[z1];
                    index[z1] = j;
                    z1++;
                    np++;
                    
                    /* Apply Householder transformations to cols in new â„¤ */
                    if (z1 < n) {
                        for (jz = z1; jz < n; jz++) {
                            jj = index[jz];
                            h2(np - 1, np, m, aj, 1, up, &a[mda * jj], 1, mda, 1);
                        }
                    }
                    
                    /* Zero sub-diagonal elements in col j */
                    for (i = np; i < m; i++) {
                        aj[i] = 0.0;
                    }
                    
                    /* Set ğ°â±¼ = 0 for j âˆˆ â„™ */
                    w[j] = 0.0;
                    break;
                }
            }
            
            /* Reject j as a candidate to be moved from â„¤ to â„™,
             * restore ğ€â‚šâ±¼ and test dual coefficients again */
            aj[np] = asave;
            w[j] = 0.0;
        }
        
        /* Inner loop: When new j joins â„™, the coefficients of the free variables
         * in the unconstrained solution ğ¬ may turn negative.
         * The inner loop continues until all violating variables have been moved to â„¤. */
        for (;;) {
            /* Compute EQP solution ğ¬ by solving triangular system ğ±ß® = [ğ‘â‚–â»Â¹:O]ğğ› */
            for (ip = np - 1; ip >= 0; ip--) {
                if (ip < np - 1) {
                    jj = index[ip + 1];
                    daxpy(ip + 1, -z[ip + 1], &a[mda * jj], 1, z, 1);
                }
                jj = index[ip];
                z[ip] /= a[ip + mda * jj];
            }
            
            /* Check iteration count */
            if (++iter > maxIter) {
                *rnorm = (np < m) ? dnrm2(m - np, &b[np], 1) : 0.0;
                return 1;  /* Exceeded max iterations */
            }
            
            /* See if all new constrained coefficients are feasible.
             * Find index t âˆˆ â„™ such that ğ±â‚œ/(ğ±â‚œ-ğ³â‚œ) = ğšŠğš›ğš ğš–ğš’ğš— { ğ±â±¼/(ğ±â±¼-ğ³â±¼) : ğ³â±¼ â‰¤ 0, j âˆˆ â„™ } */
            alpha = 2.0;
            jj = -1;
            for (ip = 0; ip < np; ip++) {
                l = index[ip];
                if (z[ip] <= 0.0) {
                    /* Found unfeasible coefficient, compute alpha.
                     * É‘ = ğ±â‚œ/(ğ±â‚œ-ğ³â‚œ) */
                    t = -x[l] / (z[ip] - x[l]);
                    if (alpha > t) {
                        alpha = t;
                        jj = ip;
                    }
                }
            }
            
            /* If all coefficients are feasible, exit inner loop to main loop */
            if (jj < 0) {
                for (ip = 0; ip < np; ip++) {
                    l = index[ip];
                    x[l] = z[ip];
                }
                break;
            }
            
            /* Interpolate between x and z: ğ± = ğ± + É‘(ğ¬ - ğ±) */
            for (ip = 0; ip < np; ip++) {
                l = index[ip];
                x[l] += alpha * (z[ip] - x[l]);
            }
            
            /* Move coefficient i from â„™ to â„¤ */
            i = index[jj];
            for (;;) {
                x[i] = 0.0;
                if (++jj < np) {
                    for (j = jj; j < np; j++) {
                        ii = index[j];
                        double* ci = &a[mda * ii];
                        index[j - 1] = ii;
                        g1(ci[j - 1], ci[j], &cc, &ss, &ci[j - 1]);
                        ci[j] = 0.0;
                        for (l = 0; l < n; l++) {
                            if (l != ii) {
                                double* cl = &a[mda * l];
                                g2(cc, ss, &cl[j - 1], &cl[j]);
                            }
                        }
                        g2(cc, ss, &b[j - 1], &b[j]);
                    }
                }
                
                np--;
                z1--;
                index[z1] = i;
                
                /* See if the remaining coefficients in â„™ are feasible.
                 * They should be because of the way É‘ was determined.
                 * If any are infeasible, it is due to round-off error.
                 * Any that are non-positive will be set to zero and moved from â„™ to â„¤. */
                break;
            }
            
            /* Copy b into z, then solve again and loop back */
            memcpy(z, b, m * sizeof(double));
        }
    }
    
compute_rnorm:
    /* Calculate norm-2 of the residual vector: â€–ğáµ€ğ›â‚‚â€–â‚‚ */
    if (np < m) {
        *rnorm = dnrm2(m - np, &b[np], 1);
    } else {
        *rnorm = 0.0;
        for (i = 0; i < n; i++) {
            w[i] = 0.0;
        }
    }
    return 0;  /* Success */
}
